{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":3136,"databundleVersionId":26502,"sourceType":"competition"}],"dockerImageVersionId":31153,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Import Libraries","metadata":{}},{"cell_type":"code","source":"# %load_ext autoreload\n%reload_ext autoreload\n%autoreload 2\n\nimport os\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport string\nfrom IPython import display\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import roc_curve, auc, accuracy_score, classification_report, confusion_matrix, roc_auc_score\nfrom sklearn.model_selection import StratifiedKFold","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-23T15:24:09.040716Z","iopub.execute_input":"2025-10-23T15:24:09.041081Z","iopub.status.idle":"2025-10-23T15:24:09.093862Z","shell.execute_reply.started":"2025-10-23T15:24:09.041050Z","shell.execute_reply":"2025-10-23T15:24:09.092701Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"params_cfg = {\n    \"action\"   : \"main_feat01\",  \n    \"feat_path\": \"../../../exps/featbase_19102025/data.npz\",\n    \"seed\"    : 42, # Set random seed\n    \"exp_dir\" : os.path.abspath('../../../exps'),\n    'exp_name': 'trainbase_19102025',\n    \"data_dir\": os.path.abspath(\"../../data/titanic\"),\n    \"verbose\" : True,\n}\nparams_cfg.update(**{\n    \"save_dir\": os.path.abspath(f'{params_cfg[\"exp_dir\"]}/{params_cfg[\"exp_name\"]}')\n})\n\nfor v in params_cfg:\n    print(f'+ {v}: {params_cfg[v]}')\n\nglobals().update(**params_cfg)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-23T15:24:09.095368Z","iopub.execute_input":"2025-10-23T15:24:09.095657Z","iopub.status.idle":"2025-10-23T15:24:09.141932Z","shell.execute_reply.started":"2025-10-23T15:24:09.095636Z","shell.execute_reply":"2025-10-23T15:24:09.140959Z"}},"outputs":[{"name":"stdout","text":"+ action: main_feat01\n+ feat_path: ../../../exps/featbase_19102025/data.npz\n+ seed: 42\n+ exp_dir: /exps\n+ exp_name: trainbase_19102025\n+ data_dir: /data/titanic\n+ verbose: True\n+ save_dir: /exps/trainbase_19102025\n","output_type":"stream"}],"execution_count":11},{"cell_type":"markdown","source":"## Data Load","metadata":{}},{"cell_type":"code","source":"# data_dir = '../../../data/titanic'\n# df_train = pd.read_csv(f'{data_dir}/train.csv')\n# df_test = pd.read_csv(f'{data_dir}/test.csv')\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\ndf_train = pd.read_csv(\"/kaggle/input/titanic/train.csv\")\ndf_train.head()\ndf_test = pd.read_csv(\"/kaggle/input/titanic/test.csv\")\ndf_test.head()\n\nif params_cfg[\"verbose\"]:\n    print(\"-\"*10, \"information\", \"-\"*10)\n    print(f'train-col: {set(df_train.columns)}')\n    print(f'test-col: {set(df_test.columns)}')\n    print(\"Union:\", set(df_train.columns).intersection(set(df_test.columns)))\n    print(\"Difference:\", set(df_train.columns).difference(set(df_test.columns)))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-23T15:24:09.142803Z","iopub.execute_input":"2025-10-23T15:24:09.143201Z","iopub.status.idle":"2025-10-23T15:24:09.200548Z","shell.execute_reply.started":"2025-10-23T15:24:09.143177Z","shell.execute_reply":"2025-10-23T15:24:09.199687Z"},"jupyter":{"source_hidden":true}},"outputs":[{"name":"stdout","text":"/kaggle/input/titanic/train.csv\n/kaggle/input/titanic/test.csv\n/kaggle/input/titanic/gender_submission.csv\n---------- information ----------\ntrain-col: {'Fare', 'SibSp', 'Parch', 'Sex', 'Age', 'Cabin', 'Embarked', 'Ticket', 'Survived', 'Name', 'Pclass', 'PassengerId'}\ntest-col: {'Fare', 'SibSp', 'Parch', 'Sex', 'Age', 'Cabin', 'Embarked', 'Ticket', 'Name', 'Pclass', 'PassengerId'}\nUnion: {'Fare', 'SibSp', 'Parch', 'Sex', 'Age', 'Embarked', 'Ticket', 'Name', 'Pclass', 'Cabin', 'PassengerId'}\nDifference: {'Survived'}\n","output_type":"stream"}],"execution_count":12},{"cell_type":"markdown","source":"## Preprocessing","metadata":{}},{"cell_type":"code","source":"def preprocessing_feature_01(df_data, is_train = True, is_debug = True, **kwargs):\n    df_output = pd.DataFrame()\n\n    # Sex: gioi tinh\n    cls_sex = {'female': 0, 'male' : 1}\n    df_output[\"Sex\"] = df_data[\"Sex\"].apply(lambda x: cls_sex[x])\n    # Age: median\n    df_output[\"Age\"] = df_data[\"Age\"].fillna(df_data[\"Age\"].median())\n    # Fare, Pclass\n    for name in ['Fare', 'Pclass', 'SibSp', 'Parch']:\n        df_output[name] = df_data[name]\n    # Cabin\n    cls_cabin = {'A':1, 'B':2, 'C':3, 'D':4, 'E':5, 'F':6, 'G':7, 'T':8, 'Z':0}\n    df_output[\"Cabin\"] = df_data['Cabin'].apply(lambda x: cls_cabin['Z'] if pd.isna(x) else cls_cabin[x[0]])\n    # Embarked\n    cls_embarked = {'0': 0, 'C':1, 'Q':2, 'S':3}\n    df_output[\"Embarked\"] =  df_data['Embarked'].apply(lambda x: cls_embarked['0'] if pd.isna(x) else cls_embarked[x])\n    # Surname\n    surnames = ['Capt.', 'Col.', 'Don.', 'Dr.', 'Jonkheer.', 'Lady.', 'Major.', \n            'Master.', 'Miss.', 'Mlle.', 'Mme.', 'Mr.', 'Mrs.', 'Ms.', 'Rev.', 'Sir.', 'the']\n    cls_surnames = dict(zip(surnames, range(len(surnames))))\n    df_output[\"Surname\"] = df_data['Name'].apply(lambda x: cls_surnames[x.split(',')[1].split(' ')[1]])\n\n    if is_train:\n        df_output[\"Output\"] = df_data[\"Survived\"]\n\n    # display.display(df_output)\n\n    if is_debug:\n        print(\"head(10)\")\n        print(display.display(df_data.head(5)))\n        print(\"tail(10)\")\n        print(display.display(df_data.tail(5)))\n        print(\"isna\")\n        display.display(df_data.isna().sum())\n        # Sex: gioi tinh\n        print(\"sex\")\n        display.display(np.unique(df_data['Sex'], return_counts=True))\n        # Age: lay median\n        print(f'Age IsNa: {df_data[\"Age\"].isna().sum()}')\n        print(f\"Age Median: {df_data['Age'].median()}\")\n        # Fare\n        display.display(df_data[\"Fare\"].describe())\n        # Cabin\n        print(\"-*10\", \"Cabin\")\n        display.display(np.unique(df_data['Cabin'].apply(\n            lambda x: 'Z0' if pd.isna(x) else x), return_counts=True))\n        # Embarked\n        display.display(\n            np.unique(df_data['Embarked'].apply(lambda x: '0' if pd.isna(x) else x), return_counts=True)\n        )\n        globals().update(**locals())\n    \n    return df_output, None\n    pass\n\npreprocessing_feature_01(df_train)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-23T15:24:09.201946Z","iopub.execute_input":"2025-10-23T15:24:09.202206Z","iopub.status.idle":"2025-10-23T15:24:09.310839Z","shell.execute_reply.started":"2025-10-23T15:24:09.202187Z","shell.execute_reply":"2025-10-23T15:24:09.309839Z"}},"outputs":[{"name":"stdout","text":"head(10)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"   PassengerId  Survived  Pclass  \\\n0            1         0       3   \n1            2         1       1   \n2            3         1       3   \n3            4         1       1   \n4            5         0       3   \n\n                                                Name     Sex   Age  SibSp  \\\n0                            Braund, Mr. Owen Harris    male  22.0      1   \n1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n2                             Heikkinen, Miss. Laina  female  26.0      0   \n3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n4                           Allen, Mr. William Henry    male  35.0      0   \n\n   Parch            Ticket     Fare Cabin Embarked  \n0      0         A/5 21171   7.2500   NaN        S  \n1      0          PC 17599  71.2833   C85        C  \n2      0  STON/O2. 3101282   7.9250   NaN        S  \n3      0            113803  53.1000  C123        S  \n4      0            373450   8.0500   NaN        S  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PassengerId</th>\n      <th>Survived</th>\n      <th>Pclass</th>\n      <th>Name</th>\n      <th>Sex</th>\n      <th>Age</th>\n      <th>SibSp</th>\n      <th>Parch</th>\n      <th>Ticket</th>\n      <th>Fare</th>\n      <th>Cabin</th>\n      <th>Embarked</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0</td>\n      <td>3</td>\n      <td>Braund, Mr. Owen Harris</td>\n      <td>male</td>\n      <td>22.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>A/5 21171</td>\n      <td>7.2500</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n      <td>female</td>\n      <td>38.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>PC 17599</td>\n      <td>71.2833</td>\n      <td>C85</td>\n      <td>C</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>1</td>\n      <td>3</td>\n      <td>Heikkinen, Miss. Laina</td>\n      <td>female</td>\n      <td>26.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>STON/O2. 3101282</td>\n      <td>7.9250</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>1</td>\n      <td>1</td>\n      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n      <td>female</td>\n      <td>35.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>113803</td>\n      <td>53.1000</td>\n      <td>C123</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>0</td>\n      <td>3</td>\n      <td>Allen, Mr. William Henry</td>\n      <td>male</td>\n      <td>35.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>373450</td>\n      <td>8.0500</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"name":"stdout","text":"None\ntail(10)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"     PassengerId  Survived  Pclass                                      Name  \\\n886          887         0       2                     Montvila, Rev. Juozas   \n887          888         1       1              Graham, Miss. Margaret Edith   \n888          889         0       3  Johnston, Miss. Catherine Helen \"Carrie\"   \n889          890         1       1                     Behr, Mr. Karl Howell   \n890          891         0       3                       Dooley, Mr. Patrick   \n\n        Sex   Age  SibSp  Parch      Ticket   Fare Cabin Embarked  \n886    male  27.0      0      0      211536  13.00   NaN        S  \n887  female  19.0      0      0      112053  30.00   B42        S  \n888  female   NaN      1      2  W./C. 6607  23.45   NaN        S  \n889    male  26.0      0      0      111369  30.00  C148        C  \n890    male  32.0      0      0      370376   7.75   NaN        Q  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PassengerId</th>\n      <th>Survived</th>\n      <th>Pclass</th>\n      <th>Name</th>\n      <th>Sex</th>\n      <th>Age</th>\n      <th>SibSp</th>\n      <th>Parch</th>\n      <th>Ticket</th>\n      <th>Fare</th>\n      <th>Cabin</th>\n      <th>Embarked</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>886</th>\n      <td>887</td>\n      <td>0</td>\n      <td>2</td>\n      <td>Montvila, Rev. Juozas</td>\n      <td>male</td>\n      <td>27.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>211536</td>\n      <td>13.00</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>887</th>\n      <td>888</td>\n      <td>1</td>\n      <td>1</td>\n      <td>Graham, Miss. Margaret Edith</td>\n      <td>female</td>\n      <td>19.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>112053</td>\n      <td>30.00</td>\n      <td>B42</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>888</th>\n      <td>889</td>\n      <td>0</td>\n      <td>3</td>\n      <td>Johnston, Miss. Catherine Helen \"Carrie\"</td>\n      <td>female</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>2</td>\n      <td>W./C. 6607</td>\n      <td>23.45</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>889</th>\n      <td>890</td>\n      <td>1</td>\n      <td>1</td>\n      <td>Behr, Mr. Karl Howell</td>\n      <td>male</td>\n      <td>26.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>111369</td>\n      <td>30.00</td>\n      <td>C148</td>\n      <td>C</td>\n    </tr>\n    <tr>\n      <th>890</th>\n      <td>891</td>\n      <td>0</td>\n      <td>3</td>\n      <td>Dooley, Mr. Patrick</td>\n      <td>male</td>\n      <td>32.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>370376</td>\n      <td>7.75</td>\n      <td>NaN</td>\n      <td>Q</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"name":"stdout","text":"None\nisna\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"PassengerId      0\nSurvived         0\nPclass           0\nName             0\nSex              0\nAge            177\nSibSp            0\nParch            0\nTicket           0\nFare             0\nCabin          687\nEmbarked         2\ndtype: int64"},"metadata":{}},{"name":"stdout","text":"sex\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"(array(['female', 'male'], dtype=object), array([314, 577]))"},"metadata":{}},{"name":"stdout","text":"Age IsNa: 177\nAge Median: 28.0\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"count    891.000000\nmean      32.204208\nstd       49.693429\nmin        0.000000\n25%        7.910400\n50%       14.454200\n75%       31.000000\nmax      512.329200\nName: Fare, dtype: float64"},"metadata":{}},{"name":"stdout","text":"-*10 Cabin\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"(array(['A10', 'A14', 'A16', 'A19', 'A20', 'A23', 'A24', 'A26', 'A31',\n        'A32', 'A34', 'A36', 'A5', 'A6', 'A7', 'B101', 'B102', 'B18',\n        'B19', 'B20', 'B22', 'B28', 'B3', 'B30', 'B35', 'B37', 'B38',\n        'B39', 'B4', 'B41', 'B42', 'B49', 'B5', 'B50', 'B51 B53 B55',\n        'B57 B59 B63 B66', 'B58 B60', 'B69', 'B71', 'B73', 'B77', 'B78',\n        'B79', 'B80', 'B82 B84', 'B86', 'B94', 'B96 B98', 'C101', 'C103',\n        'C104', 'C106', 'C110', 'C111', 'C118', 'C123', 'C124', 'C125',\n        'C126', 'C128', 'C148', 'C2', 'C22 C26', 'C23 C25 C27', 'C30',\n        'C32', 'C45', 'C46', 'C47', 'C49', 'C50', 'C52', 'C54', 'C62 C64',\n        'C65', 'C68', 'C7', 'C70', 'C78', 'C82', 'C83', 'C85', 'C86',\n        'C87', 'C90', 'C91', 'C92', 'C93', 'C95', 'C99', 'D', 'D10 D12',\n        'D11', 'D15', 'D17', 'D19', 'D20', 'D21', 'D26', 'D28', 'D30',\n        'D33', 'D35', 'D36', 'D37', 'D45', 'D46', 'D47', 'D48', 'D49',\n        'D50', 'D56', 'D6', 'D7', 'D9', 'E10', 'E101', 'E12', 'E121',\n        'E17', 'E24', 'E25', 'E31', 'E33', 'E34', 'E36', 'E38', 'E40',\n        'E44', 'E46', 'E49', 'E50', 'E58', 'E63', 'E67', 'E68', 'E77',\n        'E8', 'F E69', 'F G63', 'F G73', 'F2', 'F33', 'F38', 'F4', 'G6',\n        'T', 'Z0'], dtype=object),\n array([  1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n          1,   1,   1,   1,   2,   1,   2,   2,   2,   1,   1,   2,   1,\n          1,   1,   1,   1,   1,   2,   2,   1,   2,   2,   2,   1,   1,\n          1,   2,   1,   1,   1,   1,   1,   1,   4,   1,   1,   1,   1,\n          1,   1,   1,   2,   2,   2,   2,   1,   1,   2,   3,   4,   1,\n          1,   1,   1,   1,   1,   1,   2,   1,   1,   2,   2,   1,   1,\n          2,   1,   2,   1,   1,   1,   1,   1,   2,   2,   1,   1,   3,\n          1,   1,   1,   2,   1,   2,   1,   2,   1,   1,   2,   2,   2,\n          1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   3,\n          1,   2,   1,   2,   2,   1,   2,   1,   1,   1,   1,   2,   1,\n          1,   1,   1,   1,   2,   1,   1,   2,   1,   1,   2,   3,   3,\n          1,   2,   4,   1, 687]))"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"(array(['0', 'C', 'Q', 'S'], dtype=object), array([  2, 168,  77, 644]))"},"metadata":{}},{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"(     Sex   Age     Fare  Pclass  SibSp  Parch  Cabin  Embarked  Surname  \\\n 0      1  22.0   7.2500       3      1      0      0         3       11   \n 1      0  38.0  71.2833       1      1      0      3         1       12   \n 2      0  26.0   7.9250       3      0      0      0         3        8   \n 3      0  35.0  53.1000       1      1      0      3         3       12   \n 4      1  35.0   8.0500       3      0      0      0         3       11   \n ..   ...   ...      ...     ...    ...    ...    ...       ...      ...   \n 886    1  27.0  13.0000       2      0      0      0         3       14   \n 887    0  19.0  30.0000       1      0      0      2         3        8   \n 888    0  28.0  23.4500       3      1      2      0         3        8   \n 889    1  26.0  30.0000       1      0      0      3         1       11   \n 890    1  32.0   7.7500       3      0      0      0         2       11   \n \n      Output  \n 0         0  \n 1         1  \n 2         1  \n 3         1  \n 4         0  \n ..      ...  \n 886       0  \n 887       1  \n 888       0  \n 889       1  \n 890       0  \n \n [891 rows x 10 columns],\n None)"},"metadata":{}}],"execution_count":13},{"cell_type":"markdown","source":"## FEATURE ENGINEERING","metadata":{}},{"cell_type":"code","source":"print(\"\\n=== FEATURE ENGINEERING ===\")\n\n# 4.1. Trích xuất Title từ Name\ndf_train['Title'] = df_train['Name'].str.extract(' ([A-Za-z]+)\\.', expand=False)\ndf_test['Title'] = df_test['Name'].str.extract(' ([A-Za-z]+)\\.', expand=False)\n\n# Nhóm các Title hiếm\ntitle_mapping = {\n    'Mr': 'Mr', 'Miss': 'Miss', 'Mrs': 'Mrs', 'Master': 'Master',\n    'Dr': 'Rare', 'Rev': 'Rare', 'Col': 'Rare', 'Major': 'Rare',\n    'Mlle': 'Miss', 'Countess': 'Rare', 'Ms': 'Miss', 'Lady': 'Rare',\n    'Jonkheer': 'Rare', 'Don': 'Rare', 'Dona': 'Rare', 'Mme': 'Mrs',\n    'Capt': 'Rare', 'Sir': 'Rare'\n}\ndf_train['Title'] = df_train['Title'].map(title_mapping)\ndf_test['Title'] = df_test['Title'].map(title_mapping)\n\n# 4.2. Nhóm Age theo khoảng\ndf_train['AgeGroup'] = pd.cut(df_train['Age'], bins=[0, 12, 18, 35, 60, 100],\n                              labels=['Child', 'Teen', 'Adult', 'Middle', 'Senior'])\ndf_test['AgeGroup'] = pd.cut(df_test['Age'], bins=[0, 12, 18, 35, 60, 100],\n                             labels=['Child', 'Teen', 'Adult', 'Middle', 'Senior'])\n\n# 4.3. Nhóm Fare thành 4 mức\ndf_train['FareGroup'] = pd.qcut(df_train['Fare'], 4, labels=['Low', 'Mid', 'High', 'VeryHigh'])\ndf_test['FareGroup'] = pd.qcut(df_test['Fare'], 4, labels=['Low', 'Mid', 'High', 'VeryHigh'])\n\n# 4.4. Tạo tính năng FamilySize\ndf_train['FamilySize'] = df_train['SibSp'] + df_train['Parch'] + 1\ndf_test['FamilySize'] = df_test['SibSp'] + df_test['Parch'] + 1\n\n# 4.5. Tính năng IsAlone\ndf_train['IsAlone'] = (df_train['FamilySize'] == 1).astype(int)\ndf_test['IsAlone'] = (df_test['FamilySize'] == 1).astype(int)\n\n# 4.6 Fare cho 1 người\ndf_train['Fare_per_Person'] = df_train['Fare'] / df_train['FamilySize']\n\nprint(\"✓ Hoàn thành Feature Engineering\")\n\nprint(\"\\n=== AFTER FEATURE ENGINEERING ===\")\ncols_new = ['Title', 'AgeGroup', 'FareGroup', 'FamilySize', 'IsAlone', 'Fare_per_Person']\nprint(df_train[cols_new].head(10))\n\nprint(\"Danh sách cột hiện tại:\")\nprint(df_train.columns.tolist())\n\nprint(df_train[['Title', 'AgeGroup', 'FareGroup', 'FamilySize', 'IsAlone', 'Fare_per_Person']].describe(include='all'))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-23T15:24:09.312569Z","iopub.execute_input":"2025-10-23T15:24:09.312921Z","iopub.status.idle":"2025-10-23T15:24:09.397101Z","shell.execute_reply.started":"2025-10-23T15:24:09.312870Z","shell.execute_reply":"2025-10-23T15:24:09.396245Z"}},"outputs":[{"name":"stdout","text":"\n=== FEATURE ENGINEERING ===\n✓ Hoàn thành Feature Engineering\n\n=== AFTER FEATURE ENGINEERING ===\n    Title AgeGroup FareGroup  FamilySize  IsAlone  Fare_per_Person\n0      Mr    Adult       Low           2        0          3.62500\n1     Mrs   Middle  VeryHigh           2        0         35.64165\n2    Miss    Adult       Mid           1        1          7.92500\n3     Mrs    Adult  VeryHigh           2        0         26.55000\n4      Mr    Adult       Mid           1        1          8.05000\n5      Mr      NaN       Mid           1        1          8.45830\n6      Mr   Middle  VeryHigh           1        1         51.86250\n7  Master    Child      High           5        0          4.21500\n8     Mrs    Adult       Mid           3        0          3.71110\n9     Mrs     Teen      High           2        0         15.03540\nDanh sách cột hiện tại:\n['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp', 'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked', 'Title', 'AgeGroup', 'FareGroup', 'FamilySize', 'IsAlone', 'Fare_per_Person']\n       Title AgeGroup FareGroup  FamilySize     IsAlone  Fare_per_Person\ncount    891      714       891  891.000000  891.000000       891.000000\nunique     5        5         4         NaN         NaN              NaN\ntop       Mr    Adult       Mid         NaN         NaN              NaN\nfreq     517      358       224         NaN         NaN              NaN\nmean     NaN      NaN       NaN    1.904602    0.602694        19.916375\nstd      NaN      NaN       NaN    1.613459    0.489615        35.841257\nmin      NaN      NaN       NaN    1.000000    0.000000         0.000000\n25%      NaN      NaN       NaN    1.000000    0.000000         7.250000\n50%      NaN      NaN       NaN    1.000000    1.000000         8.300000\n75%      NaN      NaN       NaN    2.000000    1.000000        23.666667\nmax      NaN      NaN       NaN   11.000000    1.000000       512.329200\n","output_type":"stream"}],"execution_count":14},{"cell_type":"markdown","source":"## ENCODING","metadata":{}},{"cell_type":"code","source":"# Sex → số\ndf_train['Sex'] = df_train['Sex'].map({'male': 1, 'female': 0})\ndf_test['Sex'] = df_test['Sex'].map({'male': 1, 'female': 0})\n\n# One-hot encoding\ncategorical_cols = ['Embarked', 'Pclass', 'Title', 'AgeGroup', 'FareGroup']\ndf_train = pd.get_dummies(df_train, columns=categorical_cols, drop_first=False)\ndf_test = pd.get_dummies(df_test, columns=categorical_cols, drop_first=False)\n\n# Đồng bộ cột giữa train và test\ndf_test = df_test.reindex(columns=df_train.columns, fill_value=0)\n\nprint(\"✓ Hoàn thành Encoding\")\n\nmissing_in_test = set(df_train.columns) - set(df_test.columns)\nextra_in_test = set(df_test.columns) - set(df_train.columns)\n\nprint(\"Thiếu trong test:\", missing_in_test)\nprint(\"Thừa trong test:\", extra_in_test)\n\nprint(df_train.head())\nencoded_cols = [col for col in df_train.columns if any(prefix in col for prefix in ['Embarked_', 'Pclass_', 'Title_', 'AgeGroup_', 'FareGroup_'])]\nprint(df_train[encoded_cols].head())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-23T15:24:09.398175Z","iopub.execute_input":"2025-10-23T15:24:09.398440Z","iopub.status.idle":"2025-10-23T15:24:09.469439Z","shell.execute_reply.started":"2025-10-23T15:24:09.398414Z","shell.execute_reply":"2025-10-23T15:24:09.468589Z"}},"outputs":[{"name":"stdout","text":"✓ Hoàn thành Encoding\nThiếu trong test: set()\nThừa trong test: set()\n   PassengerId  Survived                                               Name  \\\n0            1         0                            Braund, Mr. Owen Harris   \n1            2         1  Cumings, Mrs. John Bradley (Florence Briggs Th...   \n2            3         1                             Heikkinen, Miss. Laina   \n3            4         1       Futrelle, Mrs. Jacques Heath (Lily May Peel)   \n4            5         0                           Allen, Mr. William Henry   \n\n   Sex   Age  SibSp  Parch            Ticket     Fare Cabin  ...  Title_Rare  \\\n0    1  22.0      1      0         A/5 21171   7.2500   NaN  ...       False   \n1    0  38.0      1      0          PC 17599  71.2833   C85  ...       False   \n2    0  26.0      0      0  STON/O2. 3101282   7.9250   NaN  ...       False   \n3    0  35.0      1      0            113803  53.1000  C123  ...       False   \n4    1  35.0      0      0            373450   8.0500   NaN  ...       False   \n\n   AgeGroup_Child  AgeGroup_Teen  AgeGroup_Adult  AgeGroup_Middle  \\\n0           False          False            True            False   \n1           False          False           False             True   \n2           False          False            True            False   \n3           False          False            True            False   \n4           False          False            True            False   \n\n   AgeGroup_Senior  FareGroup_Low  FareGroup_Mid  FareGroup_High  \\\n0            False           True          False           False   \n1            False          False          False           False   \n2            False          False           True           False   \n3            False          False          False           False   \n4            False          False           True           False   \n\n   FareGroup_VeryHigh  \n0               False  \n1                True  \n2               False  \n3                True  \n4               False  \n\n[5 rows x 33 columns]\n   Embarked_C  Embarked_Q  Embarked_S  Pclass_1  Pclass_2  Pclass_3  \\\n0       False       False        True     False     False      True   \n1        True       False       False      True     False     False   \n2       False       False        True     False     False      True   \n3       False       False        True      True     False     False   \n4       False       False        True     False     False      True   \n\n   Title_Master  Title_Miss  Title_Mr  Title_Mrs  Title_Rare  AgeGroup_Child  \\\n0         False       False      True      False       False           False   \n1         False       False     False       True       False           False   \n2         False        True     False      False       False           False   \n3         False       False     False       True       False           False   \n4         False       False      True      False       False           False   \n\n   AgeGroup_Teen  AgeGroup_Adult  AgeGroup_Middle  AgeGroup_Senior  \\\n0          False            True            False            False   \n1          False           False             True            False   \n2          False            True            False            False   \n3          False            True            False            False   \n4          False            True            False            False   \n\n   FareGroup_Low  FareGroup_Mid  FareGroup_High  FareGroup_VeryHigh  \n0           True          False           False               False  \n1          False          False           False                True  \n2          False           True           False               False  \n3          False          False           False                True  \n4          False           True           False               False  \n","output_type":"stream"}],"execution_count":15},{"cell_type":"markdown","source":"## SCALING","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\n\ntarget = 'Survived'\nfeature_cols = [\n    c for c in df_train.columns \n    if c != target and c not in ['PassengerId', 'Name', 'Ticket', 'Cabin']\n]\nnum_cols = ['Age', 'Fare', 'SibSp', 'Parch'] \ncat_cols = ['Sex', 'Embarked', 'Pclass', 'Title', 'AgeGroup', 'FareGroup']\nnum_cols = [c for c in df_train.select_dtypes(include=['int64', 'float64']).columns if c in feature_cols]\nif 'Survived' in num_cols:\n    num_cols.remove('Survived') \n\n# One-hot encode các biến phân loại\ndf_train = pd.get_dummies(df_train, drop_first=True)\ndf_test = pd.get_dummies(df_test, drop_first=True)\n\n# Căn chỉnh cột giữa train/test cho khớp nhau\ndf_test = df_test.reindex(columns=df_train.columns, fill_value=0)\n\nprint(\"\\nTrước khi Scaled:\")\nprint(display.display(df_train[num_cols].describe()))\n\nscaler = StandardScaler()\ndf_train[num_cols] = scaler.fit_transform(df_train[num_cols])\ndf_test[num_cols] = scaler.transform(df_test[num_cols])\n\n\nprint(\"\\nSau khi Scaled:\")\nprint(display.display(df_train[num_cols].describe()))\n\nprint(\"✓ Hoàn thành Scaling\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-23T15:24:09.471471Z","iopub.execute_input":"2025-10-23T15:24:09.471782Z","iopub.status.idle":"2025-10-23T15:24:09.598052Z","shell.execute_reply.started":"2025-10-23T15:24:09.471763Z","shell.execute_reply":"2025-10-23T15:24:09.597089Z"}},"outputs":[{"name":"stdout","text":"\nTrước khi Scaled:\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"              Sex         Age       SibSp       Parch        Fare  FamilySize  \\\ncount  891.000000  714.000000  891.000000  891.000000  891.000000  891.000000   \nmean     0.647587   29.699118    0.523008    0.381594   32.204208    1.904602   \nstd      0.477990   14.526497    1.102743    0.806057   49.693429    1.613459   \nmin      0.000000    0.420000    0.000000    0.000000    0.000000    1.000000   \n25%      0.000000   20.125000    0.000000    0.000000    7.910400    1.000000   \n50%      1.000000   28.000000    0.000000    0.000000   14.454200    1.000000   \n75%      1.000000   38.000000    1.000000    0.000000   31.000000    2.000000   \nmax      1.000000   80.000000    8.000000    6.000000  512.329200   11.000000   \n\n          IsAlone  Fare_per_Person  \ncount  891.000000       891.000000  \nmean     0.602694        19.916375  \nstd      0.489615        35.841257  \nmin      0.000000         0.000000  \n25%      0.000000         7.250000  \n50%      1.000000         8.300000  \n75%      1.000000        23.666667  \nmax      1.000000       512.329200  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Sex</th>\n      <th>Age</th>\n      <th>SibSp</th>\n      <th>Parch</th>\n      <th>Fare</th>\n      <th>FamilySize</th>\n      <th>IsAlone</th>\n      <th>Fare_per_Person</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>891.000000</td>\n      <td>714.000000</td>\n      <td>891.000000</td>\n      <td>891.000000</td>\n      <td>891.000000</td>\n      <td>891.000000</td>\n      <td>891.000000</td>\n      <td>891.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>0.647587</td>\n      <td>29.699118</td>\n      <td>0.523008</td>\n      <td>0.381594</td>\n      <td>32.204208</td>\n      <td>1.904602</td>\n      <td>0.602694</td>\n      <td>19.916375</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>0.477990</td>\n      <td>14.526497</td>\n      <td>1.102743</td>\n      <td>0.806057</td>\n      <td>49.693429</td>\n      <td>1.613459</td>\n      <td>0.489615</td>\n      <td>35.841257</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.000000</td>\n      <td>0.420000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>0.000000</td>\n      <td>20.125000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>7.910400</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>7.250000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>1.000000</td>\n      <td>28.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>14.454200</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>8.300000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>1.000000</td>\n      <td>38.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>31.000000</td>\n      <td>2.000000</td>\n      <td>1.000000</td>\n      <td>23.666667</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>1.000000</td>\n      <td>80.000000</td>\n      <td>8.000000</td>\n      <td>6.000000</td>\n      <td>512.329200</td>\n      <td>11.000000</td>\n      <td>1.000000</td>\n      <td>512.329200</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"name":"stdout","text":"None\n\nSau khi Scaled:\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"                Sex           Age         SibSp         Parch          Fare  \\\ncount  8.910000e+02  7.140000e+02  8.910000e+02  8.910000e+02  8.910000e+02   \nmean  -1.315820e-16  2.388379e-16  3.588600e-17  5.681949e-17 -1.993666e-18   \nstd    1.000562e+00  1.000701e+00  1.000562e+00  1.000562e+00  1.000562e+00   \nmin   -1.355574e+00 -2.016979e+00 -4.745452e-01 -4.736736e-01 -6.484217e-01   \n25%   -1.355574e+00 -6.595416e-01 -4.745452e-01 -4.736736e-01 -4.891482e-01   \n50%    7.376951e-01 -1.170488e-01 -4.745452e-01 -4.736736e-01 -3.573909e-01   \n75%    7.376951e-01  5.718310e-01  4.327934e-01 -4.736736e-01 -2.424635e-02   \nmax    7.376951e-01  3.465126e+00  6.784163e+00  6.974147e+00  9.667167e+00   \n\n         FamilySize       IsAlone  Fare_per_Person  \ncount  8.910000e+02  8.910000e+02     8.910000e+02  \nmean  -2.392400e-17 -7.974666e-17    -2.791133e-17  \nstd    1.000562e+00  1.000562e+00     1.000562e+00  \nmin   -5.609748e-01 -1.231645e+00    -5.559950e-01  \n25%   -5.609748e-01 -1.231645e+00    -3.536006e-01  \n50%   -5.609748e-01  8.119223e-01    -3.242883e-01  \n75%    5.915988e-02  8.119223e-01     1.046949e-01  \nmax    5.640372e+00  8.119223e-01     1.374643e+01  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Sex</th>\n      <th>Age</th>\n      <th>SibSp</th>\n      <th>Parch</th>\n      <th>Fare</th>\n      <th>FamilySize</th>\n      <th>IsAlone</th>\n      <th>Fare_per_Person</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>8.910000e+02</td>\n      <td>7.140000e+02</td>\n      <td>8.910000e+02</td>\n      <td>8.910000e+02</td>\n      <td>8.910000e+02</td>\n      <td>8.910000e+02</td>\n      <td>8.910000e+02</td>\n      <td>8.910000e+02</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>-1.315820e-16</td>\n      <td>2.388379e-16</td>\n      <td>3.588600e-17</td>\n      <td>5.681949e-17</td>\n      <td>-1.993666e-18</td>\n      <td>-2.392400e-17</td>\n      <td>-7.974666e-17</td>\n      <td>-2.791133e-17</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>1.000562e+00</td>\n      <td>1.000701e+00</td>\n      <td>1.000562e+00</td>\n      <td>1.000562e+00</td>\n      <td>1.000562e+00</td>\n      <td>1.000562e+00</td>\n      <td>1.000562e+00</td>\n      <td>1.000562e+00</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>-1.355574e+00</td>\n      <td>-2.016979e+00</td>\n      <td>-4.745452e-01</td>\n      <td>-4.736736e-01</td>\n      <td>-6.484217e-01</td>\n      <td>-5.609748e-01</td>\n      <td>-1.231645e+00</td>\n      <td>-5.559950e-01</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>-1.355574e+00</td>\n      <td>-6.595416e-01</td>\n      <td>-4.745452e-01</td>\n      <td>-4.736736e-01</td>\n      <td>-4.891482e-01</td>\n      <td>-5.609748e-01</td>\n      <td>-1.231645e+00</td>\n      <td>-3.536006e-01</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>7.376951e-01</td>\n      <td>-1.170488e-01</td>\n      <td>-4.745452e-01</td>\n      <td>-4.736736e-01</td>\n      <td>-3.573909e-01</td>\n      <td>-5.609748e-01</td>\n      <td>8.119223e-01</td>\n      <td>-3.242883e-01</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>7.376951e-01</td>\n      <td>5.718310e-01</td>\n      <td>4.327934e-01</td>\n      <td>-4.736736e-01</td>\n      <td>-2.424635e-02</td>\n      <td>5.915988e-02</td>\n      <td>8.119223e-01</td>\n      <td>1.046949e-01</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>7.376951e-01</td>\n      <td>3.465126e+00</td>\n      <td>6.784163e+00</td>\n      <td>6.974147e+00</td>\n      <td>9.667167e+00</td>\n      <td>5.640372e+00</td>\n      <td>8.119223e-01</td>\n      <td>1.374643e+01</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"name":"stdout","text":"None\n✓ Hoàn thành Scaling\n","output_type":"stream"}],"execution_count":16},{"cell_type":"markdown","source":"## Train","metadata":{}},{"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.ensemble import VotingClassifier\nfrom sklearn.metrics import (\n    accuracy_score, f1_score, roc_auc_score, \n    precision_score, recall_score, classification_report, confusion_matrix\n)\nfrom sklearn.model_selection import cross_val_score, StratifiedKFold, GridSearchCV\nfrom sklearn.preprocessing import LabelEncoder, StandardScaler\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.utils.multiclass import type_of_target\nimport numpy as np\nimport pandas as pd\n\n# === Chuẩn bị dữ liệu ===\ntarget = 'Survived'\nfeature_cols = [c for c in df_train.columns if c != target]\n\n# Encode các cột dạng chuỗi\nfor col in df_train.select_dtypes(include=['object']).columns:\n    le = LabelEncoder()\n    df_train[col] = le.fit_transform(df_train[col].astype(str))\n    if col in df_test.columns:\n        # tránh lỗi khi test có giá trị chưa thấy trong train\n        df_test[col] = df_test[col].map(lambda x: x if x in le.classes_ else le.classes_[0])\n        df_test[col] = le.transform(df_test[col].astype(str))\n\n# Khớp cột giữa train/test\ndf_test = df_test.reindex(columns=feature_cols, fill_value=0)\n\nX_train_full = df_train[feature_cols].fillna(0)\ny_train_full = df_train[target]\nX_test = df_test.fillna(0)\n\n# === Thiết lập tham số ===\nparams = {\"random_state\": 42}\ncv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n\n# === Định nghĩa mô hình với pipeline (tự động scale) ===\nlog_clf = make_pipeline(\n    StandardScaler(),\n    LogisticRegression(max_iter=2000, solver='lbfgs', random_state=params[\"random_state\"])\n)\nsvc_clf = make_pipeline(\n    StandardScaler(),\n    SVC(kernel='rbf', probability=True, random_state=params[\"random_state\"])\n)\nknn_clf = make_pipeline(\n    StandardScaler(),\n    KNeighborsClassifier(n_neighbors=10, weights='distance', n_jobs=-1)\n)\n\n# === Lưới tham số để GridSearchCV ===\nparam_grids = {\n    'LogisticRegression': {\n        'logisticregression__C': [0.01, 0.1, 1, 10],\n        'logisticregression__solver': ['lbfgs', 'liblinear']\n    },\n    'SVC': {\n        'svc__C': [0.1, 1, 10],\n        'svc__gamma': ['scale', 'auto']\n    },\n    'KNeighbors': {\n        'kneighborsclassifier__n_neighbors': [3, 5, 7, 9, 11],\n        'kneighborsclassifier__weights': ['uniform', 'distance']\n    }\n}\n\n# === Huấn luyện GridSearchCV cho từng model ===\ngrid_results = {}\nfor name, clf in zip(['LogisticRegression', 'SVC', 'KNeighbors'], [log_clf, svc_clf, knn_clf]):\n    print(f\"\\n=== GridSearchCV cho {name} ===\")\n    grid = GridSearchCV(\n        clf,\n        param_grids[name],\n        cv=cv,\n        scoring='accuracy',\n        n_jobs=-1,\n        verbose=1\n    )\n    grid.fit(X_train_full, y_train_full)\n    grid_results[name] = grid.best_estimator_\n    print(f\"Best Params for {name}: {grid.best_params_}\")\n    print(f\"Best CV Accuracy: {grid.best_score_:.4f}\")\n\n# === Tạo Voting Ensemble ===\nvoting_clf = VotingClassifier(\n    estimators=[\n        ('lr', grid_results['LogisticRegression']),\n        ('svc', grid_results['SVC']),\n        ('knn', grid_results['KNeighbors'])\n    ],\n    voting='soft',\n    weights=[2, 1, 3]\n)\n\n# === Đánh giá ===\nmodel_map = {\n    'LogisticRegression': grid_results['LogisticRegression'],\n    'SVC': grid_results['SVC'],\n    'KNeighbors': grid_results['KNeighbors'],\n    'Voting': voting_clf\n}\n\nresults = {}\nbest_score = -1\nbest_name = None\nbest_model = None\n\nfor name, clf in model_map.items():\n    print(f\"\\nĐang đánh giá {name} ...\")\n    acc_scores = cross_val_score(clf, X_train_full, y_train_full, cv=cv, scoring='accuracy')\n    f1_scores  = cross_val_score(clf, X_train_full, y_train_full, cv=cv, scoring='f1')\n\n    target_type = type_of_target(y_train_full)\n    if target_type == 'binary':\n        roc_scores = cross_val_score(clf, X_train_full, y_train_full, cv=cv, scoring='roc_auc')\n    else:\n        roc_scores = [np.nan] * cv.get_n_splits()\n\n    results[name] = {\n        'acc_mean': np.mean(acc_scores),\n        'f1_mean': np.mean(f1_scores),\n        'roc_mean': np.nanmean(roc_scores)\n    }\n\n    print(f\"{name} | Accuracy: {np.mean(acc_scores):.4f} ± {np.std(acc_scores):.4f}\")\n    print(f\"F1-score: {np.mean(f1_scores):.4f} | ROC-AUC: {np.nanmean(roc_scores):.4f}\")\n\n    if np.mean(acc_scores) > best_score:\n        best_score = np.mean(acc_scores)\n        best_name = name\n        best_model = clf\n\n# === Tổng hợp kết quả ===\nprint(\"\\n=== Tổng hợp KFold results ===\")\nfor name, met in results.items():\n    print(f\"{name:20s} acc={met['acc_mean']:.4f} f1={met['f1_mean']:.4f} roc={met['roc_mean']:.4f}\")\nprint(f\"\\nBest model by CV accuracy: {best_name} ({best_score:.4f})\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-23T15:24:09.599226Z","iopub.execute_input":"2025-10-23T15:24:09.599538Z","iopub.status.idle":"2025-10-23T15:26:24.860788Z","shell.execute_reply.started":"2025-10-23T15:24:09.599516Z","shell.execute_reply":"2025-10-23T15:26:24.859733Z"}},"outputs":[{"name":"stdout","text":"\n=== GridSearchCV cho LogisticRegression ===\nFitting 5 folds for each of 8 candidates, totalling 40 fits\nBest Params for LogisticRegression: {'logisticregression__C': 0.01, 'logisticregression__solver': 'liblinear'}\nBest CV Accuracy: 0.8339\n\n=== GridSearchCV cho SVC ===\nFitting 5 folds for each of 6 candidates, totalling 30 fits\nBest Params for SVC: {'svc__C': 10, 'svc__gamma': 'auto'}\nBest CV Accuracy: 0.7183\n\n=== GridSearchCV cho KNeighbors ===\nFitting 5 folds for each of 10 candidates, totalling 50 fits\nBest Params for KNeighbors: {'kneighborsclassifier__n_neighbors': 11, 'kneighborsclassifier__weights': 'uniform'}\nBest CV Accuracy: 0.5872\n\nĐang đánh giá LogisticRegression ...\nLogisticRegression | Accuracy: 0.8339 ± 0.0175\nF1-score: 0.7842 | ROC-AUC: 0.8815\n\nĐang đánh giá SVC ...\nSVC | Accuracy: 0.7183 ± 0.0225\nF1-score: 0.4536 | ROC-AUC: 0.8548\n\nĐang đánh giá KNeighbors ...\nKNeighbors | Accuracy: 0.5872 ± 0.0850\nF1-score: 0.1637 | ROC-AUC: 0.5405\n\nĐang đánh giá Voting ...\nVoting | Accuracy: 0.7306 ± 0.0360\nF1-score: 0.4821 | ROC-AUC: 0.8650\n\n=== Tổng hợp KFold results ===\nLogisticRegression   acc=0.8339 f1=0.7842 roc=0.8815\nSVC                  acc=0.7183 f1=0.4536 roc=0.8548\nKNeighbors           acc=0.5872 f1=0.1637 roc=0.5405\nVoting               acc=0.7306 f1=0.4821 roc=0.8650\n\n✅ Best model by CV accuracy: LogisticRegression (0.8339)\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, classification_report, confusion_matrix\n\nfinal_model = best_model\nfinal_model.fit(X_train_full, y_train_full)\ny_pred_train = final_model.predict(X_train_full)\n\ntry:\n    y_pred_proba_train = final_model.predict_proba(X_train_full)[:, 1]\n    train_roc = roc_auc_score(y_train_full, y_pred_proba_train)\nexcept:\n    train_roc = np.nan\n\ntrain_acc = accuracy_score(y_train_full, y_pred_train)\ntrain_f1 = f1_score(y_train_full, y_pred_train)\ntrain_prec = precision_score(y_train_full, y_pred_train)\ntrain_rec = recall_score(y_train_full, y_pred_train)\n\n# ======================\n# Báo cáo & Ma trận nhầm lẫn\n# ======================\nprint(\"\\n===================== KẾT QUẢ TRÊN TẬP TRAIN (Mô hình Tối ưu) =====================\")\nprint(f\"Mô hình: {best_name}\")\nprint(f\"Accuracy : {train_acc:.4f}\")\nprint(f\"Precision: {train_prec:.4f}\")\nprint(f\"Recall   : {train_rec:.4f}\")\nprint(f\"F1 Score : {train_f1:.4f}\")\nif not np.isnan(train_roc):\n    print(f\"ROC-AUC  : {train_roc:.4f}\")\nelse:\n    print(\"ROC-AUC  : N/A\")\nprint(\"===================================================================================\")\n\nprint(\"\\n--- Classification Report ---\")\nprint(classification_report(y_train_full, y_pred_train, target_names=['Không sống sót (0)', 'Sống sót (1)']))\n\nprint(\"\\n--- Confusion Matrix ---\")\ncm = confusion_matrix(y_train_full, y_pred_train)\nprint(\"Ma trận nhầm lẫn (Dòng: Thực tế, Cột: Dự đoán):\")\nprint(cm)\n\nTN, FP, FN, TP = cm.ravel()\nprint(f\"\\nTrue Negatives (TN): {TN}\")\nprint(f\"False Positives (FP): {FP}\")\nprint(f\"False Negatives (FN): {FN}\")\nprint(f\"True Positives (TP): {TP}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-23T15:26:24.861850Z","iopub.execute_input":"2025-10-23T15:26:24.862217Z","iopub.status.idle":"2025-10-23T15:26:25.281498Z","shell.execute_reply.started":"2025-10-23T15:26:24.862189Z","shell.execute_reply":"2025-10-23T15:26:25.280518Z"}},"outputs":[{"name":"stdout","text":"\n===================== KẾT QUẢ TRÊN TẬP TRAIN (Mô hình Tối ưu) =====================\nMô hình: LogisticRegression\nAccuracy : 1.0000\nPrecision: 1.0000\nRecall   : 1.0000\nF1 Score : 1.0000\nROC-AUC  : 1.0000\n===================================================================================\n\n--- Classification Report ---\n                    precision    recall  f1-score   support\n\nKhông sống sót (0)       1.00      1.00      1.00       549\n      Sống sót (1)       1.00      1.00      1.00       342\n\n          accuracy                           1.00       891\n         macro avg       1.00      1.00      1.00       891\n      weighted avg       1.00      1.00      1.00       891\n\n\n--- Confusion Matrix ---\nMa trận nhầm lẫn (Dòng: Thực tế, Cột: Dự đoán):\n[[549   0]\n [  0 342]]\n\nTrue Negatives (TN): 549\nFalse Positives (FP): 0\nFalse Negatives (FN): 0\nTrue Positives (TP): 342\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"# Orijinal test csv'sini tekrar yükle (PassengerId için)\ntest_data_orig = pd.read_csv(\"/kaggle/input/titanic/test.csv\")\n\n# best_model ile test verisi üzerinde tahmin yap\ntest_preds = best_model.predict(X_test)\n\n# Submission dataframe'i oluştur\nsubmission = pd.DataFrame({\n    \"PassengerId\": test_data_orig[\"PassengerId\"],\n    \"Survived\": test_preds\n})\n\n# CSV olarak kaydet (kaggle ortamında)\nsubmission.to_csv(\"submission.csv\", index=False)\n\nprint(\"Submission file 'submission.csv' created.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-23T15:26:25.282618Z","iopub.execute_input":"2025-10-23T15:26:25.282942Z","iopub.status.idle":"2025-10-23T15:26:25.365020Z","shell.execute_reply.started":"2025-10-23T15:26:25.282894Z","shell.execute_reply":"2025-10-23T15:26:25.363988Z"}},"outputs":[{"name":"stdout","text":"Submission file 'submission.csv' created.\n","output_type":"stream"}],"execution_count":19},{"cell_type":"markdown","source":"## End","metadata":{}}]}